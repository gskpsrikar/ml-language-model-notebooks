{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89321cec",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "- tensorflow==2.0 or pytorch\n",
    "- pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e3912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 65.76953125 MB\n",
      "Memory usage: 315.99609375 MB\n",
      "CPU times: total: 3.22 s\n",
      "Wall time: 45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def memory_usage():\n",
    "    # Track the memory utilized by the jupyter notebook\n",
    "    import psutil\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    mem_usage = mem_info.rss / (1024 * 1024)\n",
    "    print(\"Memory usage:\", mem_usage, \"MB\")\n",
    "    \n",
    "memory_usage()\n",
    "from transformers import pipeline\n",
    "memory_usage()\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3f7a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to roberta-large-mnli and revision 130fb28 (https://huggingface.co/roberta-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at roberta-large-mnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 2679.12109375 MB\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task=\"zero-shot-classification\")\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9079f28f",
   "metadata": {},
   "source": [
    "## Inference\n",
    "- Tranformers model directly used on train set of [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/competitions/nlp-getting-started/overview)\n",
    "- Accuracy = 57.19%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3c5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"G:/kaggle_nlp_with_disaster_tweets/data/train.csv\"\n",
    "df = pd.read_csv(PATH, usecols=['text', 'target'])\n",
    "\n",
    "def predict(input_string):\n",
    "    labels = [\"NOT DISASTER\", \"DISASTER\"]\n",
    "    res = classifier(input_string, candidate_labels=[\"NOT DISASTER\", \"DISASTER\"])\n",
    "    scores = res['scores']\n",
    "    return labels.index(res['labels'][scores.index(max(scores))])\n",
    "\n",
    "df['prediction'] = df.apply(lambda x: predict(x.text), axis=1) # Took ~5 hours to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c5fc87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.191645868908445\n"
     ]
    }
   ],
   "source": [
    "## Accuracy\n",
    "correct = 0\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i]['prediction'] == df.iloc[i]['target']:\n",
    "        correct += 1\n",
    "print(correct * 100 / len(df))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
